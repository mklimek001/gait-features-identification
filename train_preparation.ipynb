{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0191c29c-7f7e-4780-b870-fff289599da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0cb655-603b-4038-b5f4-4ecd67f4c801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 2])\n",
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.],\n",
      "         [ 5.,  6.],\n",
      "         [ 7.,  8.],\n",
      "         [ 9., 10.]]])\n",
      "torch.Size([1, 3, 1])\n",
      "tensor([[[ 0.5524],\n",
      "         [ 5.2233],\n",
      "         [-3.0487]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# x = torch.randn(1, 5, 2)\n",
    "x = torch.from_numpy(np.array([[[1,2], [3,4], [5,6], [7, 8], [9, 10]]])).float()\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "conv1d = nn.Conv1d(in_channels=5, out_channels=3, kernel_size=2)\n",
    "\n",
    "output = conv1d(x)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbbccff-0460-4240-87ca-753e5b033fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.],\n",
      "         [ 5.,  6.],\n",
      "         [ 7.,  8.],\n",
      "         [ 9., 10.]]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b010f8-18d7-4c1e-bf03-09cee86baf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5524],\n",
      "         [ 5.2233],\n",
      "         [-3.0487]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b66fd4-c06a-4c80-94bc-5d43d81effde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences with mocap data: 152\n",
      "Number of sequences with mocap data and parallel cameras: 76\n",
      "Number of sequences with mocap data, parallel cameras and after clothing change: 12\n",
      "Number of unique participants with mocap data and parallel cameras: 32\n",
      "Number of unique participants with mocap data, parallel cameras and after clothing change: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'p26', 'p27', 'p28', 'p29', 'p30', 'p31'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.parsers import parse_sequences as parse_sequence_info\n",
    "\n",
    "file_path = 'gait3d\\\\ListOfSequences.txt'\n",
    "sequences = parse_sequence_info(file_path)\n",
    "\n",
    "mocap_keys = []\n",
    "par_cam_keys = []\n",
    "par_cam_person = set()\n",
    "par_after_cloth_change_keys = []\n",
    "par_after_cloth_change_person = set()\n",
    "\n",
    "for key, params in sequences.items():\n",
    "    if params['MoCap_data']:\n",
    "        mocap_keys.append(key)\n",
    "        if key[-1] in [\"1\", \"3\", \"5\", \"7\"]:\n",
    "            par_cam_keys.append(key)\n",
    "            par_cam_person.add(key[:-2])\n",
    "        if key[-1] in [\"5\", \"7\"]:\n",
    "            par_after_cloth_change_keys.append(key)\n",
    "            par_after_cloth_change_person.add(key[:-2])\n",
    "\n",
    "print(f\"Number of sequences with mocap data: {len(mocap_keys)}\")\n",
    "print(f\"Number of sequences with mocap data and parallel cameras: {len(par_cam_keys)}\")\n",
    "print(f\"Number of sequences with mocap data, parallel cameras and after clothing change: {len(par_after_cloth_change_keys)}\")\n",
    "print(f\"Number of unique participants with mocap data and parallel cameras: {len(par_cam_person)}\")\n",
    "print(f\"Number of unique participants with mocap data, parallel cameras and after clothing change: {len(par_after_cloth_change_person)}\")\n",
    "par_after_cloth_change_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3395950f-6678-499e-a788-0d60ec5327ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sequences: ['p16s1', 'p16s3', 'p13s1', 'p13s3', 'p4s1', 'p4s3', 'p29s5', 'p29s7', 'p26s5', 'p26s7']\n",
      "valid sequences: ['p8s1', 'p8s3', 'p19s1', 'p19s3', 'p3s1', 'p3s3', 'p31s5', 'p31s7', 'p27s5', 'p27s7']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "without_clothing_change = []\n",
    "while len(without_clothing_change) < 6:\n",
    "    random_person = random.choice(list(par_cam_person))\n",
    "    if random_person not in par_after_cloth_change_person:\n",
    "        without_clothing_change.append(random_person)\n",
    "        par_cam_person.remove(random_person)\n",
    "\n",
    "with_clothing_change = []\n",
    "while len(with_clothing_change) < 4:\n",
    "    random_person = random.choice(list(par_after_cloth_change_person))\n",
    "    with_clothing_change.append(random_person)\n",
    "    par_after_cloth_change_person.remove(random_person)\n",
    "\n",
    "\n",
    "test_seq_set = ([f'{p_seq}s{seq_idx}' for p_seq in without_clothing_change[:3] for seq_idx in [1, 3]] +\n",
    "                [f'{p_seq}s{seq_idx}' for p_seq in with_clothing_change[:2] for seq_idx in [5, 7]])\n",
    "\n",
    "valid_seq_set = ([f'{p_seq}s{seq_idx}' for p_seq in without_clothing_change[3:] for seq_idx in [1, 3]] +\n",
    "                [f'{p_seq}s{seq_idx}' for p_seq in with_clothing_change[2:] for seq_idx in [5, 7]])\n",
    "\n",
    "print(f\"test sequences: {test_seq_set}\")\n",
    "print(f\"valid sequences: {valid_seq_set}\")\n",
    "# without_clothing_change + [only_after_clothing_change] + [only_before_clothing_change]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac4b8fb8-e46b-4102-916d-869bc04310e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sequences: ['p29s1', 'p29s3', 'p17s1', 'p17s3', 'p25s1', 'p25s3', 'p18s1', 'p18s3', 'p10s1', 'p10s3', 'p30s1', 'p30s3', 'p28s1', 'p28s3', 'p14s1', 'p14s3', 'p21s1', 'p21s3', 'p23s1', 'p23s3', 'p31s1', 'p31s3', 'p7s1', 'p7s3', 'p6s1', 'p6s3', 'p15s1', 'p15s3', 'p12s1', 'p12s3', 'p1s1', 'p1s3', 'p11s1', 'p11s3', 'p32s1', 'p32s3', 'p5s1', 'p5s3', 'p20s1', 'p20s3', 'p27s1', 'p27s3', 'p22s1', 'p22s3', 'p26s1', 'p26s3', 'p24s1', 'p24s3', 'p9s1', 'p9s3', 'p2s1', 'p2s3', 'p30s5', 'p30s7', 'p28s5', 'p28s7']\n"
     ]
    }
   ],
   "source": [
    "train_seq_set = ([f'{p_seq}s{seq_idx}' for p_seq in list(par_cam_person) for seq_idx in [1, 3]] +\n",
    "                 [f'{p_seq}s{seq_idx}' for p_seq in list(par_after_cloth_change_person) for seq_idx in [5, 7]])\n",
    "\n",
    "print(f\"train sequences: {train_seq_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fd1ea23-7065-456b-a8b6-288272c37503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1s1 | train |       |      |\n",
      "p1s3 | train |       |      |\n",
      "p2s1 | train |       |      |\n",
      "p2s3 | train |       |      |\n",
      "p3s1 |       | valid |      |\n",
      "p3s3 |       | valid |      |\n",
      "p4s1 |       |       | test |\n",
      "p4s3 |       |       | test |\n",
      "p5s1 | train |       |      |\n",
      "p5s3 | train |       |      |\n",
      "p6s1 | train |       |      |\n",
      "p6s3 | train |       |      |\n",
      "p7s1 | train |       |      |\n",
      "p7s3 | train |       |      |\n",
      "p8s1 |       | valid |      |\n",
      "p8s3 |       | valid |      |\n",
      "p9s1 | train |       |      |\n",
      "p9s3 | train |       |      |\n",
      "p10s1 | train |       |      |\n",
      "p10s3 | train |       |      |\n",
      "p11s1 | train |       |      |\n",
      "p11s3 | train |       |      |\n",
      "p12s1 | train |       |      |\n",
      "p12s3 | train |       |      |\n",
      "p13s1 |       |       | test |\n",
      "p13s3 |       |       | test |\n",
      "p14s1 | train |       |      |\n",
      "p14s3 | train |       |      |\n",
      "p15s1 | train |       |      |\n",
      "p15s3 | train |       |      |\n",
      "p16s1 |       |       | test |\n",
      "p16s3 |       |       | test |\n",
      "p17s1 | train |       |      |\n",
      "p17s3 | train |       |      |\n",
      "p18s1 | train |       |      |\n",
      "p18s3 | train |       |      |\n",
      "p19s1 |       | valid |      |\n",
      "p19s3 |       | valid |      |\n",
      "p20s1 | train |       |      |\n",
      "p20s3 | train |       |      |\n",
      "p21s1 | train |       |      |\n",
      "p21s3 | train |       |      |\n",
      "p22s1 | train |       |      |\n",
      "p22s3 | train |       |      |\n",
      "p23s1 | train |       |      |\n",
      "p23s3 | train |       |      |\n",
      "p24s1 | train |       |      |\n",
      "p24s3 | train |       |      |\n",
      "p25s1 | train |       |      |\n",
      "p25s3 | train |       |      |\n",
      "p26s1 | train |       |      |\n",
      "p26s3 | train |       |      |\n",
      "p26s5 |       |       | test |\n",
      "p26s7 |       |       | test |\n",
      "p27s1 | train |       |      |\n",
      "p27s3 | train |       |      |\n",
      "p27s5 |       | valid |      |\n",
      "p27s7 |       | valid |      |\n",
      "p28s1 | train |       |      |\n",
      "p28s3 | train |       |      |\n",
      "p28s5 | train |       |      |\n",
      "p28s7 | train |       |      |\n",
      "p29s1 | train |       |      |\n",
      "p29s3 | train |       |      |\n",
      "p29s5 |       |       | test |\n",
      "p29s7 |       |       | test |\n",
      "p30s1 | train |       |      |\n",
      "p30s3 | train |       |      |\n",
      "p30s5 | train |       |      |\n",
      "p30s7 | train |       |      |\n",
      "p31s1 | train |       |      |\n",
      "p31s3 | train |       |      |\n",
      "p31s5 |       | valid |      |\n",
      "p31s7 |       | valid |      |\n",
      "p32s1 | train |       |      |\n",
      "p32s3 | train |       |      |\n"
     ]
    }
   ],
   "source": [
    "for key, params in sequences.items():\n",
    "    if params['MoCap_data']:\n",
    "        if key[-1] in [\"1\", \"3\", \"5\", \"7\"]:\n",
    "            print(f\"{key} | {'train' if key in train_seq_set else '     '} | {'valid' if key in valid_seq_set else '     '} | {'test' if key in test_seq_set else '    '} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af60bc52-4453-4753-baf2-8650f1b9b70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 56 | 77.78%\n",
      "Test size: 10 | 13.89%\n",
      "Valid size: 10 | 13.89%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_seq_set)} | {100*len(train_seq_set)/72:.2f}%\")\n",
    "print(f\"Test size: {len(test_seq_set)} | {100*len(test_seq_set)/72:.2f}%\")\n",
    "print(f\"Valid size: {len(valid_seq_set)} | {100*len(valid_seq_set)/72:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b7c786a-991b-495d-981b-ff160681af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_test_split = {\"test\": test_seq_set,\n",
    "                    \"valid\": valid_seq_set,\n",
    "                    \"train\": train_seq_set}\n",
    "\n",
    "with open(\"./datasets/train_test_split.json\", \"w\") as f:\n",
    "    json.dump(train_test_split, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a0cbbf8-68b8-4fd5-a614-a293ec8854a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "selected_names_file = \"./datasets/mediapipe/selected_joint_names.json\"\n",
    "input_data_file = \"./datasets/mediapipe/dataset_v2.json\"\n",
    "output_data_file = \"./datasets/mocap/dataset_v2.json\"\n",
    "\n",
    "with open(input_data_file, 'r') as file:\n",
    "    raw_input = json.load(file)\n",
    "\n",
    "with open(output_data_file, 'r') as file:\n",
    "    raw_output = json.load(file)\n",
    "\n",
    "with open(selected_names_file, 'r') as file:\n",
    "    selected_names = json.load(file)\n",
    "\n",
    "# selected_names.pop('15')\n",
    "# selected_names.pop('16')\n",
    "# selected_names.pop('13')\n",
    "# selected_names.pop('14')\n",
    "# selected_names\n",
    "\n",
    "with open(selected_names_file, \"w\") as f:\n",
    "    json.dump(selected_names, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8138529-b136-4a38-aeb8-2fd670c8b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "triang_data_file = \"./datasets/mediapipe/triangulation.json\"\n",
    "\n",
    "with open(triang_data_file, 'r') as file:\n",
    "    triangulation_data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac3d5644-056f-49ee-8f7a-7576605b1d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_frame': 195,\n",
       " 'number_of_frames': 135,\n",
       " 'frame_offset': 0,\n",
       " 'MoCap_data': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences['p1s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "575c6d0f-1bf2-4cfd-bb23-06698b0aa8be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames with all found mocaps: 6035\n",
      "Frames with at least one not found mocap: 3495\n",
      "Proportion: 63.33%\n"
     ]
    }
   ],
   "source": [
    "input_frames_data = {f\"c{c_idx}\": [] for c_idx in range(1, 5)}\n",
    "output_frames_data = []\n",
    "img_width = 960\n",
    "img_height = 540\n",
    "\n",
    "not_found = 0\n",
    "seq_keys_list = train_seq_set + test_seq_set + valid_seq_set\n",
    "\n",
    "for seq_key in seq_keys_list:\n",
    "    for f_idx in range(sequences[seq_key]['number_of_frames']):\n",
    "    # for f_idx in range(2):\n",
    "        curr_output_array = []\n",
    "        output_frame_dict = raw_output[seq_key][f_idx]\n",
    "        for point_idx, joint_name in selected_names.items():\n",
    "            curr_output_array.append(output_frame_dict[joint_name])\n",
    "\n",
    "        curr_output_array_np = np.array(curr_output_array)\n",
    "        # print(curr_output_array_np)\n",
    "        \n",
    "        curr_input_arrays = {f\"c{c_idx}\": [] for c_idx in range(1, 5)}\n",
    "\n",
    "        all_found = True\n",
    "        \n",
    "        for c_idx in range(1, 5):\n",
    "            input_frame_list = raw_input[seq_key][f\"c{c_idx}\"][str(f_idx)]\n",
    "            if [None, None] in input_frame_list:\n",
    "                all_found = False\n",
    "                break\n",
    "                \n",
    "            for point_idx, joint_name in selected_names.items(): \n",
    "                pixel_coords = input_frame_list[int(point_idx)]\n",
    "                curr_input_arrays[f\"c{c_idx}\"].append(pixel_coords)\n",
    "\n",
    "                # curr_input_arrays[f\"c{c_idx}\"].append([pixel_coords[0]/img_width, pixel_coords[1]/img_height])\n",
    "                # conversion from pixels to propotions if needed\n",
    "\n",
    "        # print(curr_input_arrays)\n",
    "\n",
    "        if all_found:\n",
    "            for c_idx in range(1, 5):\n",
    "                input_frames_data[f\"c{c_idx}\"].append(np.array(curr_input_arrays[f\"c{c_idx}\"]))\n",
    "            #     print(np.array(curr_input_arrays[f\"c{c_idx}\"]).shape)\n",
    "\n",
    "            # print(curr_output_array_np.shape)    \n",
    "            output_frames_data.append(curr_output_array_np)\n",
    "        else:\n",
    "            not_found += 1\n",
    "\n",
    "print(f\"Frames with all found mocaps: {len(output_frames_data)}\")\n",
    "print(f\"Frames with at least one not found mocap: {not_found}\")\n",
    "print(f\"Proportion: {100*len(output_frames_data)/(len(output_frames_data) + not_found):.2f}%\")\n",
    "# print(input_frames_data['c4'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "344e94e4-bfe0-4f41-8b96-313a4b4c4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MoCapInputDataset(Dataset):\n",
    "    def __init__(self, seq_keys_list, sequences, selected_names, raw_input, raw_output):\n",
    "        self.img_width = 960\n",
    "        self.img_height = 540\n",
    "        self.input_frames_data = {f\"c{c_idx}\": [] for c_idx in range(1, 5)}\n",
    "        self.output_frames_data = []\n",
    "        self.not_found = 0\n",
    "              \n",
    "        for seq_key in seq_keys_list:\n",
    "            for f_idx in range(sequences[seq_key]['number_of_frames']):\n",
    "                curr_output_array = []\n",
    "                output_frame_dict = raw_output[seq_key][f_idx]\n",
    "                for point_idx, joint_name in selected_names.items():\n",
    "                    curr_output_array.append(output_frame_dict[joint_name])\n",
    "        \n",
    "                curr_output_array_np = np.array(curr_output_array)*255\n",
    "                # 255 multiplier added to mocap to obtain distance in mm\n",
    "                curr_input_arrays = {f\"c{c_idx}\": [] for c_idx in range(1, 5)}\n",
    "        \n",
    "                all_found = True\n",
    "                \n",
    "                for c_idx in range(1, 5):\n",
    "                    input_frame_list = raw_input[seq_key][f\"c{c_idx}\"][str(f_idx)]\n",
    "                    if [None, None] in input_frame_list:\n",
    "                        all_found = False\n",
    "                        break\n",
    "                        \n",
    "                    for point_idx, joint_name in selected_names.items(): \n",
    "                        pixel_coords = input_frame_list[int(point_idx)]\n",
    "                        curr_input_arrays[f\"c{c_idx}\"].append(pixel_coords)\n",
    "                        # curr_input_arrays[f\"c{c_idx}\"].append(\n",
    "                        #     [pixel_coords[0]/self.img_width, \n",
    "                        #      pixel_coords[1]/self.img_height])\n",
    "        \n",
    "                if all_found:\n",
    "                    for c_idx in range(1, 5):\n",
    "                        self.input_frames_data[f\"c{c_idx}\"].append(np.array(curr_input_arrays[f\"c{c_idx}\"]))\n",
    " \n",
    "                    self.output_frames_data.append(curr_output_array_np)\n",
    "                else:\n",
    "                    self.not_found += 1\n",
    "\n",
    "        self.length = len(self.output_frames_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = [torch.from_numpy(self.input_frames_data[f\"c{c_idx}\"][idx]).float() for c_idx in range(1, 5)]  # each: (12, 2)\n",
    "        target = torch.from_numpy(self.output_frames_data[idx]).float()  # (12, 3)\n",
    "        return inputs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f156bde-e3d7-45cc-a079-92bf96a11882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna results\n",
    "best_params = {'lr': 0.005589010994074508, 'weight_decay': 1.1906353862455155e-05, 'dropout': 0.2214033785244307, 'batch_size': 64, 'activation': 'gelu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "892c20b1-9c87-462e-9fbd-525c9d6164be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = best_params['batch_size']\n",
    "\n",
    "train_ds = MoCapInputDataset(train_seq_set, sequences, selected_names, raw_input, raw_output)\n",
    "valid_ds = MoCapInputDataset(valid_seq_set, sequences, selected_names, raw_input, raw_output)\n",
    "test_ds = MoCapInputDataset(test_seq_set, sequences, selected_names, raw_input, raw_output)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76e59766-3069-480b-a536-b60b8d19493f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[0.4650, 0.6808],\n",
       "          [0.4615, 0.6887],\n",
       "          [0.4484, 0.5939],\n",
       "          [0.4334, 0.5923],\n",
       "          [0.4552, 0.4929],\n",
       "          [0.4559, 0.4906],\n",
       "          [0.4586, 0.3395],\n",
       "          [0.4598, 0.3398]]),\n",
       "  tensor([[0.4985, 0.5462],\n",
       "          [0.5093, 0.5628],\n",
       "          [0.4982, 0.4780],\n",
       "          [0.5129, 0.4851],\n",
       "          [0.4989, 0.4136],\n",
       "          [0.5176, 0.4131],\n",
       "          [0.4890, 0.3128],\n",
       "          [0.5227, 0.3134]]),\n",
       "  tensor([[0.5259, 0.6577],\n",
       "          [0.5332, 0.6965],\n",
       "          [0.5461, 0.5803],\n",
       "          [0.5527, 0.5841],\n",
       "          [0.5303, 0.4755],\n",
       "          [0.5338, 0.4780],\n",
       "          [0.5319, 0.3294],\n",
       "          [0.5367, 0.3307]]),\n",
       "  tensor([[0.5049, 0.5729],\n",
       "          [0.4981, 0.5827],\n",
       "          [0.5050, 0.5119],\n",
       "          [0.4937, 0.5094],\n",
       "          [0.5078, 0.4394],\n",
       "          [0.4880, 0.4350],\n",
       "          [0.5195, 0.3234],\n",
       "          [0.4811, 0.3169]])],\n",
       " tensor([[-193.1270,  202.0149,  -73.8722],\n",
       "         [-235.4661,   92.5106, -151.9323],\n",
       "         [-463.7959,  503.2065,  -43.6668],\n",
       "         [-263.9751,  510.6925, -207.6995],\n",
       "         [-260.0439,  938.8485,  -25.6127],\n",
       "         [-294.9344,  964.8200, -268.2512],\n",
       "         [-259.1191, 1380.6080,   51.4314],\n",
       "         [-298.0096, 1386.5828, -306.3095]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1f07f7a-c1ad-445d-a9e3-7a508024efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        dropout = 0\n",
    "        # shape (8, 2) -> reshape to (2, 8) \n",
    "        self.conv1d1 = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=2, out_channels=8, kernel_size=2, padding=1) for _ in range(4)\n",
    "        ])\n",
    "        self.conv1d2 = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=8, out_channels=1, kernel_size=2) for _ in range(4)\n",
    "        ])\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.fc1 = nn.Linear(32, 48)\n",
    "        self.dropout1 = nn.Dropout(p=dropout)\n",
    "        self.bn2 = nn.BatchNorm1d(48)\n",
    "        self.fc2 = nn.Linear(48, 32)\n",
    "        self.dropout2 = nn.Dropout(p=dropout)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.fc3 = nn.Linear(32, 24)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: 4 tensors of shape (batch, 8, 2)\n",
    "        conv_outs = []\n",
    "        for i, xi in enumerate(x):\n",
    "            xi = xi.permute(0, 2, 1)  # reshape to (batch, 2, 8) \n",
    "            # conv = self.conv1d[i](xi)     # (batch, 1, 8)\n",
    "            conv = self.conv1d1[i](xi)\n",
    "            conv = self.conv1d2[i](conv)\n",
    "            conv = conv.squeeze(1)     # (batch, 8)\n",
    "            conv_outs.append(conv)\n",
    "\n",
    "        concat = torch.cat(conv_outs, dim=1)  # (batch, 28)\n",
    "\n",
    "        out = self.bn1(concat)\n",
    "        out = F.gelu(self.bn2(self.fc1(out)))\n",
    "        out = self.dropout1(out)\n",
    "        out = F.gelu(self.bn3(self.fc2(out)))\n",
    "        out = self.dropout2(out)\n",
    "        out = self.fc3(out)  # (batch, 24)\n",
    "        out = out.view(-1, 8, 3)  # reshape to (batch, 8, 3)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2cc4302-a879-4d2d-9612-a62724207e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MPJPE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # shape (batch, 8, 3)\n",
    "        # compute euclidean distance for each point pair\n",
    "        distances = torch.norm(predictions - targets, dim=2)\n",
    "        mean_distance = distances.mean()\n",
    "        return mean_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35ca85b4-fb3e-488a-8ab9-ea1e41d9b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train MPJPE = 1627.9130, Val MPJPE = 1557.4268\n",
      "Epoch 2: Train MPJPE = 1599.3458, Val MPJPE = 1505.0625\n",
      "Epoch 3: Train MPJPE = 1542.8411, Val MPJPE = 1456.2364\n",
      "Epoch 4: Train MPJPE = 1461.3585, Val MPJPE = 1361.4021\n",
      "Epoch 5: Train MPJPE = 1356.3216, Val MPJPE = 1236.5474\n",
      "Epoch 6: Train MPJPE = 1231.0650, Val MPJPE = 1058.0344\n",
      "Epoch 7: Train MPJPE = 1089.2551, Val MPJPE = 820.4271\n",
      "Epoch 8: Train MPJPE = 938.8463, Val MPJPE = 792.6554\n",
      "Epoch 9: Train MPJPE = 790.3421, Val MPJPE = 716.9544\n",
      "Epoch 10: Train MPJPE = 647.4425, Val MPJPE = 517.6722\n",
      "Epoch 11: Train MPJPE = 522.8971, Val MPJPE = 382.8199\n",
      "Epoch 12: Train MPJPE = 428.6085, Val MPJPE = 377.9130\n",
      "Epoch 13: Train MPJPE = 356.8749, Val MPJPE = 347.4649\n",
      "Epoch 14: Train MPJPE = 310.8297, Val MPJPE = 256.4222\n",
      "Epoch 15: Train MPJPE = 286.3256, Val MPJPE = 271.2785\n",
      "Epoch 16: Train MPJPE = 247.1435, Val MPJPE = 238.0213\n",
      "Epoch 17: Train MPJPE = 253.8007, Val MPJPE = 203.0062\n",
      "Epoch 18: Train MPJPE = 239.7046, Val MPJPE = 198.9723\n",
      "Epoch 19: Train MPJPE = 239.2812, Val MPJPE = 210.4716\n",
      "Epoch 20: Train MPJPE = 213.4048, Val MPJPE = 179.8456\n",
      "Epoch 21: Train MPJPE = 231.7747, Val MPJPE = 237.0217\n",
      "Epoch 22: Train MPJPE = 234.0339, Val MPJPE = 201.1344\n",
      "Epoch 23: Train MPJPE = 227.0777, Val MPJPE = 280.1137\n",
      "Epoch 24: Train MPJPE = 220.6935, Val MPJPE = 224.0959\n",
      "Epoch 25: Train MPJPE = 208.0731, Val MPJPE = 175.9363\n",
      "Epoch 26: Train MPJPE = 207.3057, Val MPJPE = 178.0593\n",
      "Epoch 27: Train MPJPE = 219.6215, Val MPJPE = 180.0995\n",
      "Epoch 28: Train MPJPE = 211.8986, Val MPJPE = 186.8406\n",
      "Epoch 29: Train MPJPE = 209.6760, Val MPJPE = 238.5270\n",
      "Epoch 30: Train MPJPE = 212.4680, Val MPJPE = 196.6561\n",
      "Epoch 31: Train MPJPE = 192.5697, Val MPJPE = 169.7424\n",
      "Epoch 32: Train MPJPE = 212.7282, Val MPJPE = 184.2830\n",
      "Epoch 33: Train MPJPE = 205.5853, Val MPJPE = 210.2073\n",
      "Epoch 34: Train MPJPE = 200.4565, Val MPJPE = 214.2123\n",
      "Epoch 35: Train MPJPE = 201.9112, Val MPJPE = 192.5867\n",
      "Epoch 36: Train MPJPE = 204.2947, Val MPJPE = 230.3221\n",
      "Epoch 37: Train MPJPE = 198.4314, Val MPJPE = 259.9473\n",
      "Epoch 38: Train MPJPE = 187.6392, Val MPJPE = 350.5927\n",
      "Epoch 39: Train MPJPE = 189.6325, Val MPJPE = 360.0173\n",
      "Epoch 40: Train MPJPE = 191.7235, Val MPJPE = 534.5553\n",
      "Epoch 41: Train MPJPE = 188.0750, Val MPJPE = 353.9810\n",
      "Epoch 42: Train MPJPE = 187.4323, Val MPJPE = 359.3763\n",
      "Epoch 43: Train MPJPE = 193.6797, Val MPJPE = 389.2776\n",
      "Epoch 44: Train MPJPE = 197.6122, Val MPJPE = 308.0119\n",
      "Epoch 45: Train MPJPE = 180.3541, Val MPJPE = 377.6400\n",
      "Epoch 46: Train MPJPE = 198.9993, Val MPJPE = 352.1359\n",
      "Epoch 47: Train MPJPE = 170.2324, Val MPJPE = 275.6892\n",
      "Epoch 48: Train MPJPE = 186.1726, Val MPJPE = 290.8587\n",
      "Epoch 49: Train MPJPE = 188.7652, Val MPJPE = 315.6152\n",
      "Epoch 50: Train MPJPE = 169.1562, Val MPJPE = 288.1225\n",
      "Epoch 51: Train MPJPE = 187.8298, Val MPJPE = 449.7342\n",
      "Epoch 52: Train MPJPE = 181.7916, Val MPJPE = 283.5773\n",
      "Epoch 53: Train MPJPE = 176.7936, Val MPJPE = 292.0780\n",
      "Epoch 54: Train MPJPE = 184.6105, Val MPJPE = 318.8822\n",
      "Epoch 55: Train MPJPE = 179.9804, Val MPJPE = 280.6700\n",
      "Epoch 56: Train MPJPE = 182.4024, Val MPJPE = 326.3329\n",
      "Epoch 57: Train MPJPE = 184.5830, Val MPJPE = 273.8411\n",
      "Epoch 58: Train MPJPE = 173.4808, Val MPJPE = 369.8657\n",
      "Epoch 59: Train MPJPE = 179.7652, Val MPJPE = 275.8371\n",
      "Epoch 60: Train MPJPE = 182.7798, Val MPJPE = 335.3348\n",
      "Epoch 61: Train MPJPE = 167.0113, Val MPJPE = 297.2280\n",
      "Epoch 62: Train MPJPE = 168.0904, Val MPJPE = 295.1949\n",
      "Epoch 63: Train MPJPE = 162.4486, Val MPJPE = 344.2535\n",
      "Epoch 64: Train MPJPE = 175.4397, Val MPJPE = 366.1670\n",
      "Epoch 65: Train MPJPE = 169.5187, Val MPJPE = 277.4166\n",
      "Epoch 66: Train MPJPE = 168.5076, Val MPJPE = 295.8818\n",
      "Epoch 67: Train MPJPE = 182.5782, Val MPJPE = 317.6864\n",
      "Epoch 68: Train MPJPE = 177.3000, Val MPJPE = 298.1592\n",
      "Epoch 69: Train MPJPE = 171.9365, Val MPJPE = 351.4116\n",
      "Epoch 70: Train MPJPE = 166.4117, Val MPJPE = 308.1857\n",
      "Epoch 71: Train MPJPE = 173.9935, Val MPJPE = 292.9467\n",
      "Epoch 72: Train MPJPE = 173.7960, Val MPJPE = 332.2426\n",
      "Epoch 73: Train MPJPE = 168.3102, Val MPJPE = 400.7561\n",
      "Epoch 74: Train MPJPE = 171.0799, Val MPJPE = 456.8548\n",
      "Epoch 75: Train MPJPE = 161.6840, Val MPJPE = 381.1169\n",
      "Epoch 76: Train MPJPE = 171.0088, Val MPJPE = 304.7626\n",
      "Epoch 77: Train MPJPE = 174.3143, Val MPJPE = 607.2631\n",
      "Epoch 78: Train MPJPE = 162.0143, Val MPJPE = 365.8961\n",
      "Epoch 79: Train MPJPE = 165.0679, Val MPJPE = 411.1498\n",
      "Epoch 80: Train MPJPE = 160.4102, Val MPJPE = 367.8085\n",
      "Epoch 81: Train MPJPE = 158.6405, Val MPJPE = 335.6664\n",
      "Epoch 82: Train MPJPE = 172.7807, Val MPJPE = 362.8717\n",
      "Epoch 83: Train MPJPE = 169.7318, Val MPJPE = 340.9175\n",
      "Epoch 84: Train MPJPE = 168.1517, Val MPJPE = 333.9909\n",
      "Epoch 85: Train MPJPE = 150.3130, Val MPJPE = 317.6588\n",
      "Epoch 86: Train MPJPE = 155.9987, Val MPJPE = 354.4812\n",
      "Epoch 87: Train MPJPE = 163.6293, Val MPJPE = 408.7949\n",
      "Epoch 88: Train MPJPE = 163.3746, Val MPJPE = 357.5061\n",
      "Epoch 89: Train MPJPE = 159.2230, Val MPJPE = 308.4983\n",
      "Epoch 90: Train MPJPE = 161.1279, Val MPJPE = 385.4301\n",
      "Epoch 91: Train MPJPE = 154.7204, Val MPJPE = 353.5291\n",
      "Epoch 92: Train MPJPE = 173.8554, Val MPJPE = 599.8526\n",
      "Epoch 93: Train MPJPE = 159.3555, Val MPJPE = 485.2135\n",
      "Epoch 94: Train MPJPE = 156.9674, Val MPJPE = 361.1055\n",
      "Epoch 95: Train MPJPE = 161.5879, Val MPJPE = 770.0822\n",
      "Epoch 96: Train MPJPE = 158.4532, Val MPJPE = 353.3219\n",
      "Epoch 97: Train MPJPE = 173.2337, Val MPJPE = 417.1584\n",
      "Epoch 98: Train MPJPE = 157.2155, Val MPJPE = 342.7237\n",
      "Epoch 99: Train MPJPE = 143.8200, Val MPJPE = 557.6479\n",
      "Epoch 100: Train MPJPE = 148.2002, Val MPJPE = 393.8627\n",
      "Epoch 101: Train MPJPE = 158.8996, Val MPJPE = 310.4124\n",
      "Epoch 102: Train MPJPE = 146.9391, Val MPJPE = 400.1700\n",
      "Epoch 103: Train MPJPE = 143.5614, Val MPJPE = 297.4446\n",
      "Epoch 104: Train MPJPE = 144.9203, Val MPJPE = 341.3651\n",
      "Epoch 105: Train MPJPE = 149.2946, Val MPJPE = 497.1438\n",
      "Epoch 106: Train MPJPE = 146.8778, Val MPJPE = 302.4794\n",
      "Epoch 107: Train MPJPE = 138.0680, Val MPJPE = 390.2907\n",
      "Epoch 108: Train MPJPE = 136.7783, Val MPJPE = 642.0935\n",
      "Epoch 109: Train MPJPE = 142.7780, Val MPJPE = 618.3305\n",
      "Epoch 110: Train MPJPE = 137.4780, Val MPJPE = 362.2561\n",
      "Epoch 111: Train MPJPE = 142.0376, Val MPJPE = 366.3631\n",
      "Epoch 112: Train MPJPE = 139.0289, Val MPJPE = 343.5142\n",
      "Epoch 113: Train MPJPE = 145.3692, Val MPJPE = 319.1871\n",
      "Epoch 114: Train MPJPE = 145.9528, Val MPJPE = 421.0659\n",
      "Epoch 115: Train MPJPE = 139.4937, Val MPJPE = 357.3097\n",
      "Epoch 116: Train MPJPE = 141.4245, Val MPJPE = 341.9553\n",
      "Epoch 117: Train MPJPE = 137.1503, Val MPJPE = 434.2520\n",
      "Epoch 118: Train MPJPE = 134.5462, Val MPJPE = 345.9572\n",
      "Epoch 119: Train MPJPE = 139.9529, Val MPJPE = 336.7236\n",
      "Epoch 120: Train MPJPE = 139.0002, Val MPJPE = 488.8556\n",
      "Epoch 121: Train MPJPE = 141.3107, Val MPJPE = 343.7905\n",
      "Epoch 122: Train MPJPE = 136.8518, Val MPJPE = 357.1707\n",
      "Epoch 123: Train MPJPE = 137.7914, Val MPJPE = 398.3475\n",
      "Epoch 124: Train MPJPE = 147.9276, Val MPJPE = 371.6502\n",
      "Epoch 125: Train MPJPE = 142.1133, Val MPJPE = 376.3762\n",
      "Epoch 126: Train MPJPE = 143.4989, Val MPJPE = 395.0438\n",
      "Epoch 127: Train MPJPE = 123.0132, Val MPJPE = 522.6968\n",
      "Epoch 128: Train MPJPE = 130.4012, Val MPJPE = 451.9052\n",
      "Epoch 129: Train MPJPE = 119.9309, Val MPJPE = 518.6509\n",
      "Epoch 130: Train MPJPE = 131.2613, Val MPJPE = 328.0385\n",
      "Epoch 131: Train MPJPE = 123.4834, Val MPJPE = 362.4412\n",
      "Epoch 132: Train MPJPE = 138.9940, Val MPJPE = 524.3756\n",
      "Epoch 133: Train MPJPE = 133.5404, Val MPJPE = 400.0158\n",
      "Epoch 134: Train MPJPE = 133.0600, Val MPJPE = 350.9550\n",
      "Epoch 135: Train MPJPE = 136.9643, Val MPJPE = 349.2348\n",
      "Epoch 136: Train MPJPE = 122.1016, Val MPJPE = 363.1100\n",
      "Epoch 137: Train MPJPE = 128.0264, Val MPJPE = 367.8849\n",
      "Epoch 138: Train MPJPE = 124.1388, Val MPJPE = 381.2029\n",
      "Epoch 139: Train MPJPE = 124.6253, Val MPJPE = 344.6398\n",
      "Epoch 140: Train MPJPE = 131.2132, Val MPJPE = 413.4629\n",
      "Epoch 141: Train MPJPE = 122.2154, Val MPJPE = 378.2545\n",
      "Epoch 142: Train MPJPE = 131.5220, Val MPJPE = 323.1364\n",
      "Epoch 143: Train MPJPE = 135.0892, Val MPJPE = 406.4532\n",
      "Epoch 144: Train MPJPE = 129.4288, Val MPJPE = 356.4533\n",
      "Epoch 145: Train MPJPE = 128.1739, Val MPJPE = 379.6205\n",
      "Epoch 146: Train MPJPE = 125.0387, Val MPJPE = 359.2677\n",
      "Epoch 147: Train MPJPE = 117.3625, Val MPJPE = 385.7868\n",
      "Epoch 148: Train MPJPE = 129.0718, Val MPJPE = 409.6509\n",
      "Epoch 149: Train MPJPE = 131.7223, Val MPJPE = 476.2585\n",
      "Epoch 150: Train MPJPE = 122.0428, Val MPJPE = 399.4391\n",
      "Epoch 151: Train MPJPE = 132.3669, Val MPJPE = 379.7730\n",
      "Epoch 152: Train MPJPE = 131.8441, Val MPJPE = 372.7184\n",
      "Epoch 153: Train MPJPE = 131.8378, Val MPJPE = 377.2136\n",
      "Epoch 154: Train MPJPE = 128.4447, Val MPJPE = 418.6056\n",
      "Epoch 155: Train MPJPE = 127.8947, Val MPJPE = 396.0859\n",
      "Epoch 156: Train MPJPE = 129.9633, Val MPJPE = 382.4802\n",
      "Epoch 157: Train MPJPE = 125.4997, Val MPJPE = 379.7112\n",
      "Epoch 158: Train MPJPE = 119.5025, Val MPJPE = 364.6181\n",
      "Epoch 159: Train MPJPE = 127.5521, Val MPJPE = 358.9506\n",
      "Epoch 160: Train MPJPE = 113.2124, Val MPJPE = 515.8248\n",
      "Epoch 161: Train MPJPE = 125.3699, Val MPJPE = 427.7819\n",
      "Epoch 162: Train MPJPE = 132.2175, Val MPJPE = 430.4477\n",
      "Epoch 163: Train MPJPE = 124.5239, Val MPJPE = 387.9766\n",
      "Epoch 164: Train MPJPE = 124.7565, Val MPJPE = 393.9645\n",
      "Epoch 165: Train MPJPE = 131.7531, Val MPJPE = 346.6840\n",
      "Epoch 166: Train MPJPE = 129.7471, Val MPJPE = 389.3842\n",
      "Epoch 167: Train MPJPE = 119.0770, Val MPJPE = 465.9860\n",
      "Epoch 168: Train MPJPE = 123.9927, Val MPJPE = 394.9389\n",
      "Epoch 169: Train MPJPE = 132.8351, Val MPJPE = 469.6506\n",
      "Epoch 170: Train MPJPE = 128.8202, Val MPJPE = 374.8198\n",
      "Epoch 171: Train MPJPE = 121.0909, Val MPJPE = 368.9238\n",
      "Epoch 172: Train MPJPE = 118.9687, Val MPJPE = 387.5740\n",
      "Epoch 173: Train MPJPE = 130.1383, Val MPJPE = 367.0380\n",
      "Epoch 174: Train MPJPE = 131.7157, Val MPJPE = 527.3779\n",
      "Epoch 175: Train MPJPE = 135.4790, Val MPJPE = 388.0546\n",
      "Epoch 176: Train MPJPE = 125.2275, Val MPJPE = 376.6499\n",
      "Epoch 177: Train MPJPE = 130.0037, Val MPJPE = 375.7725\n",
      "Epoch 178: Train MPJPE = 116.2310, Val MPJPE = 420.7753\n",
      "Epoch 179: Train MPJPE = 123.3867, Val MPJPE = 475.7343\n",
      "Epoch 180: Train MPJPE = 113.9728, Val MPJPE = 422.0119\n",
      "Epoch 181: Train MPJPE = 121.4946, Val MPJPE = 391.8186\n",
      "Epoch 182: Train MPJPE = 130.5873, Val MPJPE = 406.3767\n",
      "Epoch 183: Train MPJPE = 125.6681, Val MPJPE = 338.7688\n",
      "Epoch 184: Train MPJPE = 116.5318, Val MPJPE = 462.3671\n",
      "Epoch 185: Train MPJPE = 124.0991, Val MPJPE = 454.5549\n",
      "Epoch 186: Train MPJPE = 121.3255, Val MPJPE = 366.2811\n",
      "Epoch 187: Train MPJPE = 118.0997, Val MPJPE = 400.9992\n",
      "Epoch 188: Train MPJPE = 111.7061, Val MPJPE = 594.2004\n",
      "Epoch 189: Train MPJPE = 120.6633, Val MPJPE = 412.4462\n",
      "Epoch 190: Train MPJPE = 110.7888, Val MPJPE = 425.6291\n",
      "Epoch 191: Train MPJPE = 121.4793, Val MPJPE = 425.8867\n",
      "Epoch 192: Train MPJPE = 129.3357, Val MPJPE = 406.5861\n",
      "Epoch 193: Train MPJPE = 132.0052, Val MPJPE = 377.1422\n",
      "Epoch 194: Train MPJPE = 113.7064, Val MPJPE = 399.1815\n",
      "Epoch 195: Train MPJPE = 119.1711, Val MPJPE = 374.6439\n",
      "Epoch 196: Train MPJPE = 112.7347, Val MPJPE = 486.2482\n",
      "Epoch 197: Train MPJPE = 123.7245, Val MPJPE = 413.6906\n",
      "Epoch 198: Train MPJPE = 117.5673, Val MPJPE = 337.0475\n",
      "Epoch 199: Train MPJPE = 129.2011, Val MPJPE = 367.9793\n",
      "Epoch 200: Train MPJPE = 109.8960, Val MPJPE = 370.3373\n"
     ]
    }
   ],
   "source": [
    "model = CustomNet()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n",
    "# criterion = torch.nn.MSELoss()\n",
    "criterion = MPJPE()\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = [inp.float() for inp in inputs]\n",
    "        targets = targets.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * targets.size(0)\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = [inp.float() for inp in inputs]\n",
    "            targets = targets.float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * targets.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train MPJPE = {avg_train_loss:.4f}, Val MPJPE = {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d14e160c-abb0-499a-9704-1bf0d5b2fc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 275.6595\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item() * targets.size(0)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print(f\"Test loss = {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc4859f1-23f8-4258-88f1-52e73fe1f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(model, inputs_list, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    inputs = [torch.from_numpy(inp).float().unsqueeze(0).to(device) for inp in inputs_list]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(inputs) \n",
    "    \n",
    "    return output.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05504998-252d-43f4-a2de-dc1094ee3dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6.90322208404541, 3.6994009017944336, -3.9581351280212402],\n",
       " [7.050997257232666, 1.9678819179534912, -4.278520107269287],\n",
       " [7.196775913238525, 0.25871431827545166, -4.5949249267578125],\n",
       " [6.4067840576171875, 3.712695360183716, -5.024971008300781],\n",
       " [6.647609710693359, 1.9436155557632446, -5.044170379638672],\n",
       " [6.8671674728393555, 0.3317227363586426, -5.061561107635498],\n",
       " [7.128551483154297, 5.347268104553223, -3.8196592330932617],\n",
       " [7.222786903381348, 4.209889888763428, -3.9270873069763184],\n",
       " [7.1465840339660645, 3.58955454826355, -3.8218801021575928],\n",
       " [6.4526262283325195, 5.434737682342529, -4.97758674621582],\n",
       " [6.611799716949463, 4.247878551483154, -5.248648166656494],\n",
       " [6.399296283721924, 3.629312753677368, -5.209601402282715]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(raw_output[test_seq_set[0]][0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "688109ed-9ebc-45a3-8ae6-28968d7d4588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p13s1\n",
      "[[-8.251530647277832, 3.844074249267578, 0.7468725442886353], [-8.001875877380371, 2.0354771614074707, 0.5258227586746216], [-7.313557147979736, 0.5287668704986572, 0.39559948444366455], [-8.215202331542969, 3.807081937789917, -0.3815429210662842], [-8.524124145507812, 2.0546159744262695, -0.1751963347196579], [-8.814669609069824, 0.403894305229187, 0.020141497254371643], [-8.087128639221191, 5.645803451538086, 0.9305919408798218], [-8.333471298217773, 4.343874931335449, 0.9740116000175476], [-8.786253929138184, 3.8658547401428223, 1.0251011848449707], [-8.0086669921875, 5.5879950523376465, -0.4180036783218384], [-7.919554710388184, 4.258255958557129, -0.49406713247299194], [-8.123318672180176, 3.650397300720215, -0.5934985280036926]]\n",
      "\n",
      "[[102.1602198670949, -1822.8256934190747, 131.24888403694953], [9.131663350769033, -2158.727828409204, 123.0044462706963], [144.36682717263608, -1982.0813164831154, 504.9846829937159], [-6.836637753528645, -2106.9630355077556, 512.7716947321197], [167.0520390818335, -1993.0137155137668, 886.852264508659], [-16.96435386002495, -1987.942343883873, 884.7876293857464], [244.3556597656028, -1965.186805108731, 1381.235647512369], [-75.93428737846811, -1928.3889999656094, 1363.628548510619]]\n"
     ]
    }
   ],
   "source": [
    "test_seq = test_seq_set[2]\n",
    "print(test_seq)\n",
    "frame = 110\n",
    "\n",
    "bvh_sample_data = list(raw_output[test_seq][frame].values())\n",
    "triangulation_sample_all_data = triangulation_data[test_seq][frame]\n",
    "triangulation_sample_data = [triangulation_sample_all_data[int(j_idx)] for j_idx in selected_names.keys()]\n",
    "print(bvh_sample_data)\n",
    "print()\n",
    "print(triangulation_sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73cf4ecc-a65d-4e20-99f3-e508e82cb239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.20813051, 0.70449907],\n",
       "        [0.16183747, 0.69482696],\n",
       "        [0.17008203, 0.60033315],\n",
       "        [0.16713762, 0.59231079],\n",
       "        [0.16044874, 0.49173686],\n",
       "        [0.1793174 , 0.48987851],\n",
       "        [0.14938203, 0.34869745],\n",
       "        [0.18506591, 0.3496685 ]]),\n",
       " array([[0.49516344, 0.52987403],\n",
       "        [0.50331253, 0.52303612],\n",
       "        [0.49279758, 0.47022182],\n",
       "        [0.50423014, 0.46748048],\n",
       "        [0.49058369, 0.41310054],\n",
       "        [0.5052231 , 0.41280025],\n",
       "        [0.48446709, 0.33909434],\n",
       "        [0.51155484, 0.34280893]]),\n",
       " array([[0.78400618, 0.66194117],\n",
       "        [0.84437943, 0.67142469],\n",
       "        [0.81011289, 0.55996567],\n",
       "        [0.84866661, 0.56853324],\n",
       "        [0.81925732, 0.45377782],\n",
       "        [0.83465594, 0.46060836],\n",
       "        [0.81674045, 0.30456683],\n",
       "        [0.83668095, 0.31386459]]),\n",
       " array([[0.52538806, 0.66325176],\n",
       "        [0.50655919, 0.72549403],\n",
       "        [0.53693497, 0.56182033],\n",
       "        [0.50632167, 0.56894732],\n",
       "        [0.54407269, 0.41606939],\n",
       "        [0.50174999, 0.41244122],\n",
       "        [0.56368351, 0.21564625],\n",
       "        [0.48978338, 0.21891831]])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_width = 960\n",
    "img_height = 540\n",
    "\n",
    "mp_input_sample = []\n",
    "\n",
    "for c_idx in range(1, 5):\n",
    "    all_frames_for_camera = raw_input[test_seq][f\"c{c_idx}\"][str(frame)]\n",
    "    camera_mp_input_sample = []\n",
    "    \n",
    "    for point_idx, joint_name in selected_names.items(): \n",
    "        pixel_coords = all_frames_for_camera[int(point_idx)]\n",
    "        camera_mp_input_sample.append(pixel_coords)\n",
    "        # camera_mp_input_sample.append([pixel_coords[0]/img_width, pixel_coords[1]/img_height])\n",
    "\n",
    "    mp_input_sample.append(np.array(camera_mp_input_sample))\n",
    "    \n",
    "mp_input_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a4b9737-6623-4a1e-be25-d3dd476309e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1812.9342  ,   129.25957 ,   108.4758  ],\n",
       "       [-2149.7168  ,   129.08055 ,   -11.530312],\n",
       "       [-1947.7455  ,   506.13046 ,   146.98146 ],\n",
       "       [-2143.4973  ,   497.92108 ,   -33.88203 ],\n",
       "       [-1990.8002  ,   899.36646 ,   182.06152 ],\n",
       "       [-2001.2983  ,   892.08813 ,   -64.33371 ],\n",
       "       [-1989.7083  ,  1355.3257  ,   233.01064 ],\n",
       "       [-1970.1957  ,  1355.3562  ,   -92.08473 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = predict_single(model, mp_input_sample, 'cpu')\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d96e453-d8b5-4321-8409-a2d47635d0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_28.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "SCALE_FACTOR = 255\n",
    "\n",
    "x = [vec[2]*SCALE_FACTOR for vec in bvh_sample_data]\n",
    "y = [vec[0]*SCALE_FACTOR for vec in bvh_sample_data]\n",
    "z = [vec[1]*SCALE_FACTOR for vec in bvh_sample_data]\n",
    "\n",
    "# x_t = [vec[0]/SCALE_FACTOR for vec in triangulation_sample_data]\n",
    "# y_t = [vec[1]/SCALE_FACTOR for vec in triangulation_sample_data]\n",
    "# z_t = [vec[2]/SCALE_FACTOR for vec in triangulation_sample_data]\n",
    "\n",
    "x_t = [vec[0] for vec in triangulation_sample_data]\n",
    "y_t = [vec[1] for vec in triangulation_sample_data]\n",
    "z_t = [vec[2] for vec in triangulation_sample_data]\n",
    "\n",
    "x_p = [vec[2] for vec in predicted]\n",
    "y_p = [vec[0] for vec in predicted]\n",
    "z_p = [vec[1] for vec in predicted]\n",
    "    \n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=x, y=y, z=z,\n",
    "            mode='markers',\n",
    "            marker=dict(size=5, color='blue'),\n",
    "            hoverinfo='text',\n",
    "            name='Joints BVH'),\n",
    "        go.Scatter3d(\n",
    "            x=x_t, y=y_t, z=z_t,\n",
    "            mode='markers',\n",
    "            marker=dict(size=5, color='red'),\n",
    "            hoverinfo='text',\n",
    "            name='Joints triangulation mediapipe'),\n",
    "        go.Scatter3d(\n",
    "            x=x_p, y=y_p, z=z_p,\n",
    "            mode='markers',\n",
    "            marker=dict(size=5, color='green'),\n",
    "            hoverinfo='text',\n",
    "            name='Predicted by NN'),\n",
    "        ]\n",
    ")\n",
    "\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title='X',\n",
    "    yaxis_title='Y',\n",
    "    zaxis_title='Z',\n",
    "    xaxis=dict(range=[-6000, 6000]),\n",
    "    yaxis=dict(range=[-6000, 6000]),\n",
    "    zaxis=dict(range=[-6000, 6000]),\n",
    "    aspectmode='cube', \n",
    "),\n",
    "title='3D joints plot from bvh file',\n",
    "width=800,\n",
    "height=800\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db610651-515e-437b-aaf3-b9c3e295777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/custom_net_v1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5152622-363e-444e-8ad1-c2f1a3416d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
