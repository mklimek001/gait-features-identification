{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0191c29c-7f7e-4780-b870-fff289599da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0cb655-603b-4038-b5f4-4ecd67f4c801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 2])\n",
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.],\n",
      "         [ 5.,  6.],\n",
      "         [ 7.,  8.],\n",
      "         [ 9., 10.]]])\n",
      "torch.Size([1, 3, 1])\n",
      "tensor([[[4.9430],\n",
      "         [3.5290],\n",
      "         [5.6935]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# x = torch.randn(1, 5, 2)\n",
    "x = torch.from_numpy(np.array([[[1,2], [3,4], [5,6], [7, 8], [9, 10]]])).float()\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "conv1d = nn.Conv1d(in_channels=5, out_channels=3, kernel_size=2)\n",
    "\n",
    "output = conv1d(x)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbbccff-0460-4240-87ca-753e5b033fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.],\n",
      "         [ 5.,  6.],\n",
      "         [ 7.,  8.],\n",
      "         [ 9., 10.]]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b010f8-18d7-4c1e-bf03-09cee86baf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.9430],\n",
      "         [3.5290],\n",
      "         [5.6935]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b66fd4-c06a-4c80-94bc-5d43d81effde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences with mocap data: 146\n",
      "Number of sequences with mocap data and parallel cameras: 72\n",
      "Number of sequences with mocap data, parallel cameras and after clothing change: 12\n",
      "Number of unique participants with mocap data and parallel cameras: 30\n",
      "Number of unique participants with mocap data, parallel cameras and after clothing change: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'p26', 'p27', 'p28', 'p29', 'p30', 'p31'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.parsers import parse_sequences as parse_sequence_info\n",
    "\n",
    "file_path = 'gait3d\\\\ListOfSequences.txt'\n",
    "sequences = parse_sequence_info(file_path)\n",
    "\n",
    "mocap_keys = []\n",
    "par_cam_keys = []\n",
    "par_cam_person = set()\n",
    "par_after_cloth_change_keys = []\n",
    "par_after_cloth_change_person = set()\n",
    "\n",
    "for key, params in sequences.items():\n",
    "    if params['MoCap_data']:\n",
    "        mocap_keys.append(key)\n",
    "        if key[-1] in [\"1\", \"3\", \"5\", \"7\"]:\n",
    "            par_cam_keys.append(key)\n",
    "            par_cam_person.add(key[:-2])\n",
    "        if key[-1] in [\"5\", \"7\"]:\n",
    "            par_after_cloth_change_keys.append(key)\n",
    "            par_after_cloth_change_person.add(key[:-2])\n",
    "\n",
    "print(f\"Number of sequences with mocap data: {len(mocap_keys)}\")\n",
    "print(f\"Number of sequences with mocap data and parallel cameras: {len(par_cam_keys)}\")\n",
    "print(f\"Number of sequences with mocap data, parallel cameras and after clothing change: {len(par_after_cloth_change_keys)}\")\n",
    "print(f\"Number of unique participants with mocap data and parallel cameras: {len(par_cam_person)}\")\n",
    "print(f\"Number of unique participants with mocap data, parallel cameras and after clothing change: {len(par_after_cloth_change_person)}\")\n",
    "par_after_cloth_change_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3395950f-6678-499e-a788-0d60ec5327ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sequences: ['p14s1', 'p14s3', 'p12s1', 'p12s3', 'p17s1', 'p17s3', 'p29s5', 'p29s7', 'p28s5', 'p28s7']\n",
      "valid sequences: ['p3s1', 'p3s3', 'p15s1', 'p15s3', 'p19s1', 'p19s3', 'p26s5', 'p26s7', 'p31s5', 'p31s7']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "without_clothing_change = []\n",
    "while len(without_clothing_change) < 6:\n",
    "    random_person = random.choice(list(par_cam_person))\n",
    "    if random_person not in par_after_cloth_change_person:\n",
    "        without_clothing_change.append(random_person)\n",
    "        par_cam_person.remove(random_person)\n",
    "\n",
    "with_clothing_change = []\n",
    "while len(with_clothing_change) < 4:\n",
    "    random_person = random.choice(list(par_after_cloth_change_person))\n",
    "    with_clothing_change.append(random_person)\n",
    "    par_after_cloth_change_person.remove(random_person)\n",
    "\n",
    "\n",
    "test_seq_set = ([f'{p_seq}s{seq_idx}' for p_seq in without_clothing_change[:3] for seq_idx in [1, 3]] +\n",
    "                [f'{p_seq}s{seq_idx}' for p_seq in with_clothing_change[:2] for seq_idx in [5, 7]])\n",
    "\n",
    "valid_seq_set = ([f'{p_seq}s{seq_idx}' for p_seq in without_clothing_change[3:] for seq_idx in [1, 3]] +\n",
    "                [f'{p_seq}s{seq_idx}' for p_seq in with_clothing_change[2:] for seq_idx in [5, 7]])\n",
    "\n",
    "print(f\"test sequences: {test_seq_set}\")\n",
    "print(f\"valid sequences: {valid_seq_set}\")\n",
    "# without_clothing_change + [only_after_clothing_change] + [only_before_clothing_change]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac4b8fb8-e46b-4102-916d-869bc04310e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sequences: ['p22s1', 'p22s3', 'p8s1', 'p8s3', 'p5s1', 'p5s3', 'p21s1', 'p21s3', 'p26s1', 'p26s3', 'p9s1', 'p9s3', 'p10s1', 'p10s3', 'p11s1', 'p11s3', 'p2s1', 'p2s3', 'p28s1', 'p28s3', 'p32s1', 'p32s3', 'p23s1', 'p23s3', 'p24s1', 'p24s3', 'p25s1', 'p25s3', 'p13s1', 'p13s3', 'p29s1', 'p29s3', 'p16s1', 'p16s3', 'p31s1', 'p31s3', 'p4s1', 'p4s3', 'p7s1', 'p7s3', 'p20s1', 'p20s3', 'p1s1', 'p1s3', 'p30s1', 'p30s3', 'p27s1', 'p27s3', 'p30s5', 'p30s7', 'p27s5', 'p27s7']\n"
     ]
    }
   ],
   "source": [
    "train_seq_set = ([f'{p_seq}s{seq_idx}' for p_seq in list(par_cam_person) for seq_idx in [1, 3]] +\n",
    "                 [f'{p_seq}s{seq_idx}' for p_seq in list(par_after_cloth_change_person) for seq_idx in [5, 7]])\n",
    "\n",
    "print(f\"train sequences: {train_seq_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fd1ea23-7065-456b-a8b6-288272c37503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1s1 | train |       |      |\n",
      "p1s3 | train |       |      |\n",
      "p2s1 | train |       |      |\n",
      "p2s3 | train |       |      |\n",
      "p3s1 |       | valid |      |\n",
      "p3s3 |       | valid |      |\n",
      "p4s1 | train |       |      |\n",
      "p4s3 | train |       |      |\n",
      "p5s1 | train |       |      |\n",
      "p5s3 | train |       |      |\n",
      "p7s1 | train |       |      |\n",
      "p7s3 | train |       |      |\n",
      "p8s1 | train |       |      |\n",
      "p8s3 | train |       |      |\n",
      "p9s1 | train |       |      |\n",
      "p9s3 | train |       |      |\n",
      "p10s1 | train |       |      |\n",
      "p10s3 | train |       |      |\n",
      "p11s1 | train |       |      |\n",
      "p11s3 | train |       |      |\n",
      "p12s1 |       |       | test |\n",
      "p12s3 |       |       | test |\n",
      "p13s1 | train |       |      |\n",
      "p13s3 | train |       |      |\n",
      "p14s1 |       |       | test |\n",
      "p14s3 |       |       | test |\n",
      "p15s1 |       | valid |      |\n",
      "p15s3 |       | valid |      |\n",
      "p16s1 | train |       |      |\n",
      "p16s3 | train |       |      |\n",
      "p17s1 |       |       | test |\n",
      "p17s3 |       |       | test |\n",
      "p19s1 |       | valid |      |\n",
      "p19s3 |       | valid |      |\n",
      "p20s1 | train |       |      |\n",
      "p20s3 | train |       |      |\n",
      "p21s1 | train |       |      |\n",
      "p21s3 | train |       |      |\n",
      "p22s1 | train |       |      |\n",
      "p22s3 | train |       |      |\n",
      "p23s1 | train |       |      |\n",
      "p23s3 | train |       |      |\n",
      "p24s1 | train |       |      |\n",
      "p24s3 | train |       |      |\n",
      "p25s1 | train |       |      |\n",
      "p25s3 | train |       |      |\n",
      "p26s1 | train |       |      |\n",
      "p26s3 | train |       |      |\n",
      "p26s5 |       | valid |      |\n",
      "p26s7 |       | valid |      |\n",
      "p27s1 | train |       |      |\n",
      "p27s3 | train |       |      |\n",
      "p27s5 | train |       |      |\n",
      "p27s7 | train |       |      |\n",
      "p28s1 | train |       |      |\n",
      "p28s3 | train |       |      |\n",
      "p28s5 |       |       | test |\n",
      "p28s7 |       |       | test |\n",
      "p29s1 | train |       |      |\n",
      "p29s3 | train |       |      |\n",
      "p29s5 |       |       | test |\n",
      "p29s7 |       |       | test |\n",
      "p30s1 | train |       |      |\n",
      "p30s3 | train |       |      |\n",
      "p30s5 | train |       |      |\n",
      "p30s7 | train |       |      |\n",
      "p31s1 | train |       |      |\n",
      "p31s3 | train |       |      |\n",
      "p31s5 |       | valid |      |\n",
      "p31s7 |       | valid |      |\n",
      "p32s1 | train |       |      |\n",
      "p32s3 | train |       |      |\n"
     ]
    }
   ],
   "source": [
    "for key, params in sequences.items():\n",
    "    if params['MoCap_data']:\n",
    "        if key[-1] in [\"1\", \"3\", \"5\", \"7\"]:\n",
    "            print(f\"{key} | {'train' if key in train_seq_set else '     '} | {'valid' if key in valid_seq_set else '     '} | {'test' if key in test_seq_set else '    '} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af60bc52-4453-4753-baf2-8650f1b9b70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 52 | 72.22%\n",
      "Test size: 10 | 13.89%\n",
      "Valid size: 10 | 13.89%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_seq_set)} | {100*len(train_seq_set)/72:.2f}%\")\n",
    "print(f\"Test size: {len(test_seq_set)} | {100*len(test_seq_set)/72:.2f}%\")\n",
    "print(f\"Valid size: {len(valid_seq_set)} | {100*len(valid_seq_set)/72:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a0cbbf8-68b8-4fd5-a614-a293ec8854a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "selected_names_file = \"./datasets/mediapipe/selected_joint_names.json\"\n",
    "input_data_file = \"./datasets/mediapipe/dataset.json\"\n",
    "output_data_file = \"./datasets/mocap/dataset_v2.json\"\n",
    "\n",
    "with open(input_data_file, 'r') as file:\n",
    "    raw_input = json.load(file)\n",
    "\n",
    "with open(output_data_file, 'r') as file:\n",
    "    raw_output = json.load(file)\n",
    "\n",
    "with open(selected_names_file, 'r') as file:\n",
    "    selected_names = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac3d5644-056f-49ee-8f7a-7576605b1d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_frame': 195,\n",
       " 'number_of_frames': 135,\n",
       " 'frame_offset': 0,\n",
       " 'MoCap_data': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences['p1s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "575c6d0f-1bf2-4cfd-bb23-06698b0aa8be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames with all found mocaps: 5735\n",
      "Frames with at least one not found mocap: 3345\n",
      "Proportion: 63.16%\n"
     ]
    }
   ],
   "source": [
    "input_frames_data = {f\"c{c_idx}\": [] for c_idx in range(1, 5)}\n",
    "output_frames_data = []\n",
    "img_width = 960\n",
    "img_height = 540\n",
    "\n",
    "not_found = 0\n",
    "seq_keys_list = train_seq_set + test_seq_set + valid_seq_set\n",
    "\n",
    "for seq_key in seq_keys_list:\n",
    "    for f_idx in range(sequences[seq_key]['number_of_frames']):\n",
    "    # for f_idx in range(2):\n",
    "        curr_output_array = []\n",
    "        output_frame_dict = raw_output[seq_key][f_idx]\n",
    "        for point_idx, joint_name in selected_names.items():\n",
    "            curr_output_array.append(output_frame_dict[joint_name])\n",
    "\n",
    "        curr_output_array_np = np.array(curr_output_array)\n",
    "        # print(curr_output_array_np)\n",
    "        \n",
    "        curr_input_arrays = {f\"c{c_idx}\": [] for c_idx in range(1, 5)}\n",
    "\n",
    "        all_found = True\n",
    "        \n",
    "        for c_idx in range(1, 5):\n",
    "            input_frame_list = raw_input[seq_key][f\"c{c_idx}\"][str(f_idx)]\n",
    "            if [None, None] in input_frame_list:\n",
    "                all_found = False\n",
    "                break\n",
    "                \n",
    "            for point_idx, joint_name in selected_names.items(): \n",
    "                pixel_coords = input_frame_list[int(point_idx)]\n",
    "                curr_input_arrays[f\"c{c_idx}\"].append([pixel_coords[0]/img_width, pixel_coords[1]/img_height])\n",
    "                # conversion from pixels to propotions\n",
    "\n",
    "        # print(curr_input_arrays)\n",
    "\n",
    "        if all_found:\n",
    "            for c_idx in range(1, 5):\n",
    "                input_frames_data[f\"c{c_idx}\"].append(np.array(curr_input_arrays[f\"c{c_idx}\"]))\n",
    "            #     print(np.array(curr_input_arrays[f\"c{c_idx}\"]).shape)\n",
    "\n",
    "            # print(curr_output_array_np.shape)    \n",
    "            output_frames_data.append(curr_output_array_np)\n",
    "        else:\n",
    "            not_found += 1\n",
    "\n",
    "print(f\"Frames with all found mocaps: {len(output_frames_data)}\")\n",
    "print(f\"Frames with at least one not found mocap: {not_found}\")\n",
    "print(f\"Proportion: {100*len(output_frames_data)/(len(output_frames_data) + not_found):.2f}%\")\n",
    "# print(input_frames_data['c4'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344e94e4-bfe0-4f41-8b96-313a4b4c4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MoCapInputDataset(Dataset):\n",
    "    def __init__(self, seq_keys_list, sequences, selected_names, raw_input, raw_output):\n",
    "        self.img_width = 960\n",
    "        self.img_height = 540\n",
    "        self.input_frames_data = {f\"c{c_idx}\": [] for c_idx in range(1, 5)}\n",
    "        self.output_frames_data = []\n",
    "        self.not_found = 0\n",
    "              \n",
    "        for seq_key in seq_keys_list:\n",
    "            for f_idx in range(sequences[seq_key]['number_of_frames']):\n",
    "                curr_output_array = []\n",
    "                output_frame_dict = raw_output[seq_key][f_idx]\n",
    "                for point_idx, joint_name in selected_names.items():\n",
    "                    curr_output_array.append(output_frame_dict[joint_name])\n",
    "        \n",
    "                curr_output_array_np = np.array(curr_output_array)                \n",
    "                curr_input_arrays = {f\"c{c_idx}\": [] for c_idx in range(1, 5)}\n",
    "        \n",
    "                all_found = True\n",
    "                \n",
    "                for c_idx in range(1, 5):\n",
    "                    input_frame_list = raw_input[seq_key][f\"c{c_idx}\"][str(f_idx)]\n",
    "                    if [None, None] in input_frame_list:\n",
    "                        all_found = False\n",
    "                        break\n",
    "                        \n",
    "                    for point_idx, joint_name in selected_names.items(): \n",
    "                        pixel_coords = input_frame_list[int(point_idx)]\n",
    "                        curr_input_arrays[f\"c{c_idx}\"].append(\n",
    "                            [pixel_coords[0]/self.img_width, \n",
    "                             pixel_coords[1]/self.img_height])\n",
    "        \n",
    "                if all_found:\n",
    "                    for c_idx in range(1, 5):\n",
    "                        self.input_frames_data[f\"c{c_idx}\"].append(np.array(curr_input_arrays[f\"c{c_idx}\"]))\n",
    " \n",
    "                    self.output_frames_data.append(curr_output_array_np)\n",
    "                else:\n",
    "                    self.not_found += 1\n",
    "\n",
    "        self.length = len(self.output_frames_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = [torch.from_numpy(self.input_frames_data[f\"c{c_idx}\"][idx]).float() for c_idx in range(1, 5)]  # each: (12, 2)\n",
    "        target = torch.from_numpy(self.output_frames_data[idx]).float()  # (12, 3)\n",
    "        return inputs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "892c20b1-9c87-462e-9fbd-525c9d6164be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = MoCapInputDataset(train_seq_set, sequences, selected_names, raw_input, raw_output)\n",
    "valid_ds = MoCapInputDataset(valid_seq_set, sequences, selected_names, raw_input, raw_output)\n",
    "test_ds = MoCapInputDataset(test_seq_set, sequences, selected_names, raw_input, raw_output)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(valid_ds, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1f07f7a-c1ad-445d-a9e3-7a508024efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        # shape (12, 2) -> reshape to (2, 12) \n",
    "        self.conv1d = nn.Conv1d(in_channels=2, out_channels=1, kernel_size=3)  # (2, 12) -> (1, 10)\n",
    "        # flatten 4 x 10 -> 40 x 1\n",
    "        self.fc1 = nn.Linear(40, 64)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.fc2 = nn.Linear(64, 72)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.fc3 = nn.Linear(72, 36)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: 4 tensors of shape (batch, 12, 2)\n",
    "        conv_outs = []\n",
    "        for xi in x:\n",
    "            xi = xi.permute(0, 2, 1)  # reshape to (batch, 2, 12) \n",
    "            conv = self.conv1d(xi)     # (batch, 1, 10)\n",
    "            conv = conv.squeeze(1)     # (batch, 10)\n",
    "            conv_outs.append(conv)\n",
    "\n",
    "        concat = torch.cat(conv_outs, dim=1)  # (batch, 40)\n",
    "\n",
    "        out = F.relu(self.fc1(concat))\n",
    "        out = self.dropout1(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.dropout2(out)\n",
    "        out = self.fc3(out)  # (batch, 36)\n",
    "        out = out.view(-1, 12, 3)  # reshape to (batch, 12, 3)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35ca85b4-fb3e-488a-8ab9-ea1e41d9b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train MSE = 16.0531, Val MSE = 15.0439\n",
      "Epoch 2: Train MSE = 15.0646, Val MSE = 12.6524\n",
      "Epoch 3: Train MSE = 12.4248, Val MSE = 10.5646\n",
      "Epoch 4: Train MSE = 11.9016, Val MSE = 10.5103\n",
      "Epoch 5: Train MSE = 11.7848, Val MSE = 10.4494\n",
      "Epoch 6: Train MSE = 11.7179, Val MSE = 10.3682\n",
      "Epoch 7: Train MSE = 11.5440, Val MSE = 10.1415\n",
      "Epoch 8: Train MSE = 11.1025, Val MSE = 9.5402\n",
      "Epoch 9: Train MSE = 9.9309, Val MSE = 7.7670\n",
      "Epoch 10: Train MSE = 7.2402, Val MSE = 4.2998\n",
      "Epoch 11: Train MSE = 3.6670, Val MSE = 1.2477\n",
      "Epoch 12: Train MSE = 1.8192, Val MSE = 0.5175\n",
      "Epoch 13: Train MSE = 1.5302, Val MSE = 0.4610\n",
      "Epoch 14: Train MSE = 1.4694, Val MSE = 0.4670\n",
      "Epoch 15: Train MSE = 1.4520, Val MSE = 0.4686\n",
      "Epoch 16: Train MSE = 1.4424, Val MSE = 0.4554\n",
      "Epoch 17: Train MSE = 1.4199, Val MSE = 0.4372\n",
      "Epoch 18: Train MSE = 1.3933, Val MSE = 0.4511\n",
      "Epoch 19: Train MSE = 1.3757, Val MSE = 0.4571\n",
      "Epoch 20: Train MSE = 1.3629, Val MSE = 0.4393\n",
      "Epoch 21: Train MSE = 1.3396, Val MSE = 0.4431\n",
      "Epoch 22: Train MSE = 1.3212, Val MSE = 0.4212\n",
      "Epoch 23: Train MSE = 1.2988, Val MSE = 0.4145\n",
      "Epoch 24: Train MSE = 1.2799, Val MSE = 0.4178\n",
      "Epoch 25: Train MSE = 1.2557, Val MSE = 0.4169\n",
      "Epoch 26: Train MSE = 1.2406, Val MSE = 0.4207\n",
      "Epoch 27: Train MSE = 1.2286, Val MSE = 0.4210\n",
      "Epoch 28: Train MSE = 1.2305, Val MSE = 0.4123\n",
      "Epoch 29: Train MSE = 1.2283, Val MSE = 0.4078\n",
      "Epoch 30: Train MSE = 1.1856, Val MSE = 0.3905\n",
      "Epoch 31: Train MSE = 1.2005, Val MSE = 0.4030\n",
      "Epoch 32: Train MSE = 1.1731, Val MSE = 0.3965\n",
      "Epoch 33: Train MSE = 1.1835, Val MSE = 0.3919\n",
      "Epoch 34: Train MSE = 1.1675, Val MSE = 0.3949\n",
      "Epoch 35: Train MSE = 1.1535, Val MSE = 0.3939\n",
      "Epoch 36: Train MSE = 1.1491, Val MSE = 0.3774\n",
      "Epoch 37: Train MSE = 1.1467, Val MSE = 0.3823\n",
      "Epoch 38: Train MSE = 1.1162, Val MSE = 0.3730\n",
      "Epoch 39: Train MSE = 1.1059, Val MSE = 0.3759\n",
      "Epoch 40: Train MSE = 1.1172, Val MSE = 0.3756\n",
      "Epoch 41: Train MSE = 1.0893, Val MSE = 0.3655\n",
      "Epoch 42: Train MSE = 1.0812, Val MSE = 0.3729\n",
      "Epoch 43: Train MSE = 1.0880, Val MSE = 0.3674\n",
      "Epoch 44: Train MSE = 1.0737, Val MSE = 0.3619\n",
      "Epoch 45: Train MSE = 1.0927, Val MSE = 0.3693\n",
      "Epoch 46: Train MSE = 1.0587, Val MSE = 0.3550\n",
      "Epoch 47: Train MSE = 1.0779, Val MSE = 0.3622\n",
      "Epoch 48: Train MSE = 1.0611, Val MSE = 0.3575\n",
      "Epoch 49: Train MSE = 1.0201, Val MSE = 0.3570\n",
      "Epoch 50: Train MSE = 1.0294, Val MSE = 0.3572\n"
     ]
    }
   ],
   "source": [
    "model = CustomNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = [inp.float() for inp in inputs]\n",
    "        targets = targets.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * targets.size(0)\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = [inp.float() for inp in inputs]\n",
    "            targets = targets.float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * targets.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train MSE = {avg_train_loss:.4f}, Val MSE = {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d14e160c-abb0-499a-9704-1bf0d5b2fc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 0.3516\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item() * targets.size(0)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print(f\"Test loss = {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc4859f1-23f8-4258-88f1-52e73fe1f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(model, inputs_list, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    inputs = [torch.from_numpy(inp).float().unsqueeze(0).to(device) for inp in inputs_list]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(inputs) \n",
    "    \n",
    "    return output.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05504998-252d-43f4-a2de-dc1094ee3dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9.69188404083252, 4.028162002563477, 0.688791036605835],\n",
       " [9.986611366271973, 2.2449145317077637, 0.7812122702598572],\n",
       " [10.262113571166992, 0.5781108140945435, 0.867490291595459],\n",
       " [9.822742462158203, 4.075028896331787, -0.42783796787261963],\n",
       " [10.097484588623047, 2.12271785736084, -0.47968125343322754],\n",
       " [10.343533515930176, 0.37429726123809814, -0.5261550545692444],\n",
       " [10.102184295654297, 5.991581916809082, 0.7971398830413818],\n",
       " [9.823925971984863, 5.420259475708008, 1.9626073837280273],\n",
       " [9.6143217086792, 5.653244972229004, 2.547516107559204],\n",
       " [10.186217308044434, 5.998184680938721, -0.45327651500701904],\n",
       " [10.122572898864746, 5.491803169250488, -1.695825219154358],\n",
       " [9.901778221130371, 5.764641761779785, -2.3004868030548096]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(raw_output[test_seq_set[0]][0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8138529-b136-4a38-aeb8-2fd670c8b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "triang_data_file = \"./datasets/mediapipe/triangulation.json\"\n",
    "\n",
    "with open(triang_data_file, 'r') as file:\n",
    "    triangulation_data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "688109ed-9ebc-45a3-8ae6-28968d7d4588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p14s3\n",
      "[[-6.687641143798828, 3.8349709510803223, 1.019135594367981], [-6.973823070526123, 2.048238515853882, 1.0517510175704956], [-5.579444885253906, 1.135089635848999, 0.7628755569458008], [-6.719081401824951, 4.0061445236206055, -0.09257128834724426], [-7.096922397613525, 2.0806357860565186, 0.10577520728111267], [-6.847524642944336, 0.34556829929351807, 0.32260560989379883], [-6.532391548156738, 5.791557312011719, 1.118679165840149], [-6.347134113311768, 4.492308139801025, 1.3181345462799072], [-6.641845703125, 3.9046268463134766, 1.4081884622573853], [-6.535183429718018, 5.779489040374756, -0.26494431495666504], [-6.38330602645874, 4.473793983459473, -0.5415172576904297], [-6.676773548126221, 3.845623016357422, -0.6314293742179871]]\n",
      "\n",
      "[[215.5354303187731, -1418.4355213577085, 279.85629064136907], [85.44735387564796, -1737.1196495425609, 120.47440807360421], [244.96879803264895, -1729.0923372547386, 523.0504111254594], [73.85670306535584, -1749.2132575215505, 508.9235034010974], [223.64984313238241, -1678.5366079511073, 883.5334594549029], [28.546683371212048, -1663.1769133794037, 884.2231895152103], [287.3617195016279, -1614.5007303981133, 1420.7885444875105], [-25.79610758181639, -1583.9842346621122, 1417.5714184618716], [340.12307111406614, -1637.1359987805379, 1147.7194099555222], [-98.51231682259773, -1616.9065444052487, 1134.2368074840122], [380.7678782079278, -1728.236607401039, 914.450840457991], [-133.50458829090533, -1758.989648083474, 905.5144885325892]]\n"
     ]
    }
   ],
   "source": [
    "print(test_seq_set[1])\n",
    "frame = 100\n",
    "\n",
    "bvh_sample_data = list(raw_output[test_seq_set[0]][frame].values())\n",
    "triangulation_sample_all_data = triangulation_data[test_seq_set[0]][frame]\n",
    "triangulation_sample_data = [triangulation_sample_all_data[int(j_idx)] for j_idx in selected_names.keys()]\n",
    "print(bvh_sample_data)\n",
    "print()\n",
    "print(triangulation_sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73cf4ecc-a65d-4e20-99f3-e508e82cb239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.26770833, 0.67407407],\n",
       "        [0.22604167, 0.70740741],\n",
       "        [0.21041667, 0.61111111],\n",
       "        [0.22083333, 0.60185185],\n",
       "        [0.21458333, 0.50185185],\n",
       "        [0.23541667, 0.5       ],\n",
       "        [0.2125    , 0.33703704],\n",
       "        [0.24166667, 0.33518519],\n",
       "        [0.21041667, 0.42777778],\n",
       "        [0.24270833, 0.41851852],\n",
       "        [0.196875  , 0.5       ],\n",
       "        [0.22083333, 0.47592593]]),\n",
       " array([[0.490625  , 0.51481481],\n",
       "        [0.503125  , 0.52962963],\n",
       "        [0.490625  , 0.46666667],\n",
       "        [0.50416667, 0.47037037],\n",
       "        [0.49270833, 0.41296296],\n",
       "        [0.50833333, 0.41296296],\n",
       "        [0.4875    , 0.33148148],\n",
       "        [0.51458333, 0.33518519],\n",
       "        [0.48229167, 0.37407407],\n",
       "        [0.52083333, 0.37962963],\n",
       "        [0.478125  , 0.41111111],\n",
       "        [0.52395833, 0.41481481]]),\n",
       " array([[0.709375  , 0.61481481],\n",
       "        [0.76354167, 0.67037037],\n",
       "        [0.75833333, 0.55185185],\n",
       "        [0.77291667, 0.56296296],\n",
       "        [0.75625   , 0.45555556],\n",
       "        [0.77083333, 0.45925926],\n",
       "        [0.75      , 0.2962963 ],\n",
       "        [0.765625  , 0.2962963 ],\n",
       "        [0.74895833, 0.37962963],\n",
       "        [0.76979167, 0.39074074],\n",
       "        [0.76041667, 0.44259259],\n",
       "        [0.7875    , 0.46851852]]),\n",
       " array([[0.52604167, 0.52222222],\n",
       "        [0.50729167, 0.5962963 ],\n",
       "        [0.53645833, 0.48518519],\n",
       "        [0.50520833, 0.49259259],\n",
       "        [0.53333333, 0.37592593],\n",
       "        [0.5       , 0.37222222],\n",
       "        [0.54583333, 0.20740741],\n",
       "        [0.48958333, 0.20555556],\n",
       "        [0.55520833, 0.28518519],\n",
       "        [0.47604167, 0.28888889],\n",
       "        [0.56354167, 0.35925926],\n",
       "        [0.465625  , 0.36481481]])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_width = 960\n",
    "img_height = 540\n",
    "\n",
    "mp_input_sample = []\n",
    "\n",
    "for c_idx in range(1, 5):\n",
    "    all_frames_for_camera = raw_input[test_seq_set[0]][f\"c{c_idx}\"][str(frame)]\n",
    "    camera_mp_input_sample = []\n",
    "    \n",
    "    for point_idx, joint_name in selected_names.items(): \n",
    "        pixel_coords = all_frames_for_camera[int(point_idx)]\n",
    "        camera_mp_input_sample.append([pixel_coords[0]/img_width, pixel_coords[1]/img_height])\n",
    "\n",
    "    mp_input_sample.append(np.array(camera_mp_input_sample))\n",
    "    \n",
    "mp_input_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a4b9737-6623-4a1e-be25-d3dd476309e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.469159  ,  0.48426074,  0.07704934],\n",
       "       [-6.417074  ,  0.46577597, -0.24570024],\n",
       "       [-6.6621814 ,  1.839711  ,  0.16127095],\n",
       "       [-6.617307  ,  1.8023454 , -0.33486965],\n",
       "       [-6.5229716 ,  3.334403  ,  0.24297516],\n",
       "       [-6.4780607 ,  3.3174381 , -0.4377083 ],\n",
       "       [-6.4456573 ,  5.004775  ,  0.3567548 ],\n",
       "       [-6.4291835 ,  4.9952536 , -0.48991212],\n",
       "       [-6.385685  ,  3.9259408 ,  0.4254493 ],\n",
       "       [-6.3185225 ,  3.928538  , -0.5840397 ],\n",
       "       [-6.591518  ,  3.4022703 ,  0.45031327],\n",
       "       [-6.483366  ,  3.3883078 , -0.6298578 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = predict_single(model, mp_input_sample, 'cpu')\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d96e453-d8b5-4321-8409-a2d47635d0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_49.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "x = [vec[2] for vec in bvh_sample_data]\n",
    "y = [vec[0] for vec in bvh_sample_data]\n",
    "z = [vec[1] for vec in bvh_sample_data]\n",
    "\n",
    "SCALE_FACTOR = 254\n",
    "\n",
    "x_t = [vec[0]/SCALE_FACTOR for vec in triangulation_sample_data]\n",
    "y_t = [vec[1]/SCALE_FACTOR for vec in triangulation_sample_data]\n",
    "z_t = [vec[2]/SCALE_FACTOR for vec in triangulation_sample_data]\n",
    "\n",
    "x_p = [vec[2] for vec in predicted]\n",
    "y_p = [vec[0] for vec in predicted]\n",
    "z_p = [vec[1] for vec in predicted]\n",
    "    \n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=x, y=y, z=z,\n",
    "            mode='markers',\n",
    "            marker=dict(size=5, color='blue'),\n",
    "            hoverinfo='text',\n",
    "            name='Joints BVH'),\n",
    "        go.Scatter3d(\n",
    "            x=x_t, y=y_t, z=z_t,\n",
    "            mode='markers',\n",
    "            marker=dict(size=5, color='red'),\n",
    "            hoverinfo='text',\n",
    "            name='Joints triangulation mediapipe'),\n",
    "        go.Scatter3d(\n",
    "            x=x_p, y=y_p, z=z_p,\n",
    "            mode='markers',\n",
    "            marker=dict(size=5, color='green'),\n",
    "            hoverinfo='text',\n",
    "            name='Predicted by NN'),\n",
    "        ]\n",
    ")\n",
    "\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title='X',\n",
    "    yaxis_title='Y',\n",
    "    zaxis_title='Z',\n",
    "    xaxis=dict(range=[-15, 15]),\n",
    "    yaxis=dict(range=[-15, 15]),\n",
    "    zaxis=dict(range=[-15, 15]),\n",
    "    aspectmode='cube', \n",
    "),\n",
    "title='3D joints plot from bvh file',\n",
    "width=800,\n",
    "height=800\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db610651-515e-437b-aaf3-b9c3e295777b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
