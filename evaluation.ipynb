{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fc0d0a4-e4b2-4768-beef-7d900ebe9c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomNet(\n",
       "  (conv1d1): ModuleList(\n",
       "    (0-3): 4 x Conv1d(2, 8, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (conv1d2): ModuleList(\n",
       "    (0-3): 4 x Conv1d(8, 1, kernel_size=(2,), stride=(1,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=32, out_features=48, bias=True)\n",
       "  (dropout1): Dropout(p=0, inplace=False)\n",
       "  (bn2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=48, out_features=32, bias=True)\n",
       "  (dropout2): Dropout(p=0, inplace=False)\n",
       "  (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=32, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.torch_model import CustomNet\n",
    "\n",
    "model = CustomNet()\n",
    "model.load_state_dict(torch.load('./models/custom_net_yolo_v1.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dbc3416-9d03-4216-ae64-d095e0409eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sequences unique: ['p16s1', 'p16s3', 'p13s1', 'p13s3', 'p4s1', 'p4s3'] | test sequences clothing change: ['p29s5', 'p29s7', 'p26s5', 'p26s7'] \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from scripts.parsers import parse_sequences as parse_sequence_info\n",
    "from utils.torch_train_utils import get_train_valid_test_set, MoCapInputDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "file_path = 'gait3d\\\\ListOfSequences.txt'\n",
    "sequences = parse_sequence_info(file_path)\n",
    "\n",
    "selected_names_file = \"./datasets/yolo/selected_joint_names.json\"\n",
    "input_data_file = \"./datasets/yolo/dataset_v2.json\"\n",
    "output_data_file = \"./datasets/mocap/dataset_v2.json\"\n",
    "triang_data_file = \"./datasets/yolo/triangulation_v2.json\"\n",
    "\n",
    "with open(input_data_file, 'r') as file:\n",
    "    raw_input = json.load(file)\n",
    "\n",
    "with open(output_data_file, 'r') as file:\n",
    "    raw_output = json.load(file)\n",
    "\n",
    "with open(triang_data_file, 'r') as file:\n",
    "    triangulation_data = json.load(file)\n",
    "\n",
    "with open(selected_names_file, 'r') as file:\n",
    "    selected_names = json.load(file)\n",
    "\n",
    "with open(\"./datasets/train_test_split.json\", \"r\") as f:\n",
    "    train_test_split = json.load(f)\n",
    "\n",
    "test_seq_set = train_test_split[\"test\"]\n",
    "print(f\"test sequences unique: {test_seq_set[:6]} | test sequences clothing change: {test_seq_set[6:]} \")\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "test_ds_uniqe = MoCapInputDataset(test_seq_set[:6], sequences, selected_names, raw_input, raw_output)\n",
    "test_loader_uniqe = DataLoader(test_ds_uniqe, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_ds_cloth_change = MoCapInputDataset(test_seq_set[6:], sequences, selected_names, raw_input, raw_output)\n",
    "test_loader_cloth_change = DataLoader(test_ds_cloth_change, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e3a59fa-0723-447f-ba3d-ab0daa0d7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_pa_mpjpe(predicted: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute Procrustes Aligned MPJPE (PA-MPJPE).\n",
    "    \"\"\"\n",
    "    B, J, _ = predicted.shape\n",
    "    aligned_preds = []\n",
    "\n",
    "    for i in range(B):\n",
    "        pred = predicted[i]\n",
    "        gt = target[i]\n",
    "\n",
    "        # center both poses\n",
    "        pred_mean = pred.mean(dim=0, keepdim=True)\n",
    "        gt_mean = gt.mean(dim=0, keepdim=True)\n",
    "        pred_centered = pred - pred_mean\n",
    "        gt_centered = gt - gt_mean\n",
    "\n",
    "        # SVD for optimal rotation\n",
    "        H = pred_centered.T @ gt_centered\n",
    "        U, _, Vt = torch.linalg.svd(H)\n",
    "        R = Vt.T @ U.T\n",
    "\n",
    "        # reflection\n",
    "        if torch.det(R) < 0:\n",
    "            Vt[-1, :] *= -1\n",
    "            R = Vt.T @ U.T\n",
    "\n",
    "        # scale\n",
    "        var_pred = pred_centered.pow(2).sum()\n",
    "        scale = torch.trace(R @ H) / var_pred\n",
    "\n",
    "        # transform\n",
    "        pred_aligned = scale * (pred_centered @ R)\n",
    "        pred_aligned += gt_mean \n",
    "\n",
    "        aligned_preds.append(pred_aligned)\n",
    "\n",
    "    aligned_preds = torch.stack(aligned_preds, dim=0)\n",
    "    error = torch.norm(aligned_preds - target, dim=-1)\n",
    "    return error.mean()\n",
    "\n",
    "\n",
    "def compute_3dpck(predicted: torch.Tensor, target: torch.Tensor, threshold: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute 3D Percentage of Correct Keypoints (3DPCK) at a given threshold.\n",
    "    \"\"\"\n",
    "    distances = torch.norm(predicted - target, dim=-1)\n",
    "    correct = (distances < threshold).float()\n",
    "    pck = correct.mean()\n",
    "    return pck\n",
    "\n",
    "\n",
    "def compute_mpjpe(predicted: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute Mean Per Joint Position Error (MPJPE).\n",
    "    \"\"\"\n",
    "    \n",
    "    error = torch.norm(predicted - target, dim=-1)\n",
    "    return error.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd4bf87d-ad47-45fe-b34f-f15cae27bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(data_loader: DataLoader, batch_size=64) -> tuple[float]:\n",
    "    mpjpe_total = 0\n",
    "    pa_mpjpe_total = 0\n",
    "    pck200_total = 0\n",
    "    pck150_total = 0\n",
    "    pck100_total = 0\n",
    "    count = 0\n",
    "    \n",
    "    for inputs, gt_joints in data_loader:\n",
    "        with torch.no_grad():\n",
    "            predicted = model(inputs)\n",
    "            \n",
    "        mpjpe_total += compute_mpjpe(predicted, gt_joints) * batch_size\n",
    "        pa_mpjpe_total += compute_pa_mpjpe(predicted, gt_joints) * batch_size\n",
    "        pck100_total += compute_3dpck(predicted, gt_joints, threshold=100.0) * batch_size\n",
    "        pck150_total += compute_3dpck(predicted, gt_joints, threshold=150.0) * batch_size\n",
    "        pck200_total += compute_3dpck(predicted, gt_joints, threshold=200.0) * batch_size\n",
    "        count += batch_size\n",
    "    \n",
    "    mpjpe_avg = mpjpe_total / count\n",
    "    pa_mpjpe_avg = pa_mpjpe_total / count\n",
    "    pck100_avg = pck100_total / count\n",
    "    pck150_avg = pck150_total / count\n",
    "    pck200_avg = pck200_total / count\n",
    "\n",
    "    return mpjpe_avg.item(), pa_mpjpe_avg.item(), pck100_avg.item(), pck150_avg.item(), pck200_avg.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74350e3e-4ba1-4493-923a-92c354975a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ Unique sequences _ _ _\n",
      "MPJPE: 259.99 mm\n",
      "PA-MPJPE: 109.27 mm\n",
      "3DPCK@100mm: 11.51 %\n",
      "3DPCK@150mm: 36.57 %\n",
      "3DPCK@200mm: 56.87 %\n"
     ]
    }
   ],
   "source": [
    "mpjpe_avg, pa_mpjpe_avg, pck100_avg, pck150_avg, pck200_avg = calculate_metrics(test_loader_uniqe)\n",
    "\n",
    "print(\"_ _ _ Unique sequences _ _ _\")\n",
    "print(f\"MPJPE: {mpjpe_avg:.2f} mm\")\n",
    "print(f\"PA-MPJPE: {pa_mpjpe_avg:.2f} mm\")\n",
    "print(f\"3DPCK@100mm: {pck100_avg * 100:.2f} %\")\n",
    "print(f\"3DPCK@150mm: {pck150_avg * 100:.2f} %\")\n",
    "print(f\"3DPCK@200mm: {pck200_avg * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d8234b5-d161-4777-9b12-52770b7feab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ Clothing change sequences _ _ _\n",
      "MPJPE: 206.03 mm\n",
      "PA-MPJPE: 78.52 mm\n",
      "3DPCK@100mm: 6.63 %\n",
      "3DPCK@150mm: 27.97 %\n",
      "3DPCK@200mm: 55.11 %\n"
     ]
    }
   ],
   "source": [
    "mpjpe_avg, pa_mpjpe_avg, pck100_avg, pck150_avg, pck200_avg = calculate_metrics(test_loader_cloth_change)\n",
    "\n",
    "print(\"_ _ _ Clothing change sequences _ _ _\")\n",
    "print(f\"MPJPE: {mpjpe_avg:.2f} mm\")\n",
    "print(f\"PA-MPJPE: {pa_mpjpe_avg:.2f} mm\")\n",
    "print(f\"3DPCK@100mm: {pck100_avg * 100:.2f} %\")\n",
    "print(f\"3DPCK@150mm: {pck150_avg * 100:.2f} %\")\n",
    "print(f\"3DPCK@200mm: {pck200_avg * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47cca6f-0b5a-47d8-a949-9b8c88e6032d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
